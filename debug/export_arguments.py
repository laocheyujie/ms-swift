import torch
from swift.llm import ExportArguments

args = ExportArguments(
    model="/models/ZhipuAI/GLM-4.5-Air",
    model_type="glm4_5",
    model_revision=None,
    task_type="causal_lm",
    torch_dtype=torch.bfloat16,
    attn_impl=None,
    new_special_tokens=[],
    num_labels=None,
    problem_type=None,
    rope_scaling=None,
    device_map=None,
    max_memory={},
    max_model_len=None,
    local_repo_path=None,
    init_strategy=None,
    template="glm4_5",
    system=None,
    max_length=2048,
    truncation_strategy="delete",
    max_pixels=None,
    agent_template=None,
    norm_bbox=None,
    use_chat_template=True,
    padding_free=False,
    padding_side="right",
    loss_scale="default",
    sequence_parallel_size=1,
    response_prefix=None,
    template_backend="swift",
    dataset=[],
    val_dataset=[],
    split_dataset_ratio=0.0,
    data_seed=42,
    dataset_num_proc=1,
    load_from_cache_file=True,
    dataset_shuffle=True,
    val_dataset_shuffle=False,
    streaming=False,
    interleave_prob=None,
    stopping_strategy="first_exhausted",
    shuffle_buffer_size=1000,
    download_mode="reuse_dataset_if_exists",
    columns={},
    strict=False,
    remove_unused_columns=True,
    model_name=None,
    model_author=None,
    custom_dataset_info=[],
    quant_method=None,
    quant_bits=None,
    hqq_axis=None,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_storage=None,
    max_new_tokens=None,
    temperature=None,
    top_k=None,
    top_p=None,
    repetition_penalty=None,
    num_beams=1,
    stream=False,
    stop_words=[],
    logprobs=False,
    top_logprobs=None,
    ckpt_dir=None,
    lora_modules=[],
    tuner_backend="peft",
    train_type="lora",
    adapters=[],
    external_plugins=[],
    seed=42,
    model_kwargs={},
    load_args=True,
    load_data_args=False,
    packing=False,
    packing_length=None,
    lazy_tokenize=False,
    cached_dataset=[],
    custom_register_path=[],
    use_hf=False,
    hub_token=None,
    ddp_timeout=18000000,
    ddp_backend=None,
    ignore_args_error=False,
    use_swift_lora=False,
    merge_lora=False,
    safe_serialization=True,
    max_shard_size="5GB",
    output_dir="/models/ZhipuAI/GLM-4.5-Air-mcore",
    quant_n_samples=256,
    quant_batch_size=1,
    group_size=128,
    to_peft_format=False,
    to_cached_dataset=False,
    to_ollama=False,
    to_mcore=True,
    to_hf=False,
    mcore_model=None,
    mcore_adapters=[],
    thread_count=None,
    test_convert_precision=False,
    push_to_hub=False,
    hub_model_id=None,
    hub_private_repo=False,
    commit_message="update files",
    exist_ok=False,
)
